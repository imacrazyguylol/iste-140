<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copyright</title>

    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="impact.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Fraunces:ital,opsz,wght@0,9..144,100..900;1,9..144,100..900&family=Hepta+Slab:wght@1..900&family=Zen+Antique&family=Zen+Old+Mincho&display=swap"
        rel="stylesheet">
</head>

<body>
    <header>
        <a class="home" href="../">
            <h1 class="headFont">Impact</h1>
        </a>

        <nav class="headFont">
            <a id="copyright" href="../copyright/">Copyright</a>
            <a id="impact" href="#" aria-current="page">Impact</a>
            <a id="about" href="../about/">About Me</a>
            <a id="contact" href="../contact/">Contact</a>
        </nav>
    </header>

    <main>
        <section id="poison-pilling">
            <img src="assets/nightshade_example.jpg" alt="An example of a digital drawing with Nightshade applied to it. The effect is nearly unnoticable.">
            <p class="bodyFont">
                <span class="emphasize">In response</span> to the massive uprising of AI generated media, and insurmountable companies stealing their hard work and feeding it into a power-hungry technological black box for
                profit,
                artists have found numerous ways to fight back. A team at the University of Chicago has developed multiple tools designed to deter models from training on art by injecting it with
                special noise that although nearly undetectable to the human eye, completely warps the way the AI model sees the work. (Nightshade Team) This technology, sometimes referred to
                as
                “poison-pilling”, has seen growth and development over recent years as artists become more wary of models being trained on their works. The team describes their work as follows:
                “we
                propose the use of Nightshade as a powerful tool for content owners to protect their intellectual property. Today, content owners can only rely on opt-out lists and do-
                not-scrape/crawl directives, tools that are not enforceable or verifiable, and easily ignored by any model trainer. Movie studios, book publishers, game producers and individual
                artists can use systems like Nightshade to provide a strong disincentive against unauthorized data training.” Corporations are clearly unwilling to do the essential job of
                protecting
                creators and artists from having their work stolen, and for good reason: many creators, when presented the choice, would probably opt out of having their work used to train AI
                models.
                Between the effort taken to legally and ethically acquire source material for these models and the potential reduction in quality of their output due to less training data, it
                wouldn’t
                be nearly as sustainable for these companies to consensually source training data. So of course these profit-driven, multi-billion dollar companies turn to scraping literally
                everything off the web (Jones) without regard to how the creators of that data feel about it. But the apparent necessity of this practice raises the question: if we can’t train AI
                ethically, is training AI even ethical?
            </p>
            
        </section>

        <section id="ecology">
            <h2 class="headFont">Ecological impact</h2>
            <p class="bodyFont">
                One of the largest, yet quietest impacts of AI training is the ecological impact. Data centers used to train AI models operated by companies like Google, Meta, OpenAI, and others
                use
                an estimated 4.4% of all the energy in the US. Projections also show this number climbing as these data centers expand and models continue to train. The exact ecological impact is
                unclear because many of these companies refuse to give exact figures for their energy use, but “Harvard’s T.H. Chan School of Public Health found that the carbon intensity of
                electricity used by data centers was 48% higher than the US average.” (O'Donnell and Crownhart) Despite the lack of transparency from these companies, it is clear that protecting
                the
                environment is not a top priority for them. These practices are especially concerning given the current state of the climate, as our leaders begin to aggressively reverse course on
                decades of ecological progress.
            </p>
        </section>
    </main>

    <footer>
        <div>
            <h2 class="headFont">Works Cited</h2>
            <ul class="bodyFont">
                <li>
                    Bondari, Negar. “AI, Copyright, and the Law: The Ongoing Battle Over Intellectual Property Rights – IP & Technology Law Society.” USC IP & Technology Law Society, 4 February 2025,
                    https://sites.usc.edu/iptls/2025/02/04/ai-copyright-and-the-law-the-ongoing-battle-over-intellectual-property-rights/. Accessed 13 September 2025.
                </li>
                <li>
                    Jones, Nicola. “The AI revolution is running out of data. What can researchers do?” Nature, vol. 636, no. 8042, 2024, pp. 290-292. Nature.com,
                    https://www.nature.com/articles/d41586-024-03990-2. Accessed 13 September 2025.
                </li>
                <li>
                    The Nightshade Team. “[2310.13828] Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models.” arXiv, 20 October 2023, https://arxiv.org/abs/2310.13828.
                    Accessed 13 September 2025.
                </li>
                <li>
                    O'Donnell, James, and Casey Crownhart. “We did the math on AI's energy footprint. Here's the story you haven't heard.” MIT Technology Review, 20 May 2025,
                    https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/. Accessed 13 September 2025.
                </li>
                <li>
                    OpenAI. “Response to prompt asking to expand on argument.” ChatGPT, 2025, chatgpt.com. Accessed 13 September 2025.
                </li>
            </ul>
        </div>

        <p class="bodyFont attribution">&copy; 2025 Liam Rowell</p>
    </footer>
</body>

</html>